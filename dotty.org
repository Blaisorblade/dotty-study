#+STARTUP: indent

* Scala Papers
** general
- Scala Language Specification
- Unifying functional and object-oriented programming with Scala(2014)

** type system
- A core calculus for Scala type checking(2006)
- Towards equal rights for higher-kinded types(2007)
- Generics of a higher kind(2008)
- Scalable component abstractions(2005)
- The Essense of Dependent Object Types(2016)

** type classes
- Poor man’s type classes(2006)
- Type classes as objects and implicits(2010)
- Type classes are signatures of abstract types(2013)

** runtime
- Instant pickles: Generating object-oriented pickler combinators for fast and extensible serialization(2013)
- Compiling structural types on the JVM: a comparison of reflective and generative techniques from Scala's perspective(2009)

** Compiler
- Colored local type inference(2001)
- A typed intermediate language and algorithms for compiling Scala by successive rewritings(2006) PhD thesis
- Late data layout: unifying data representation transformations(2014)
- Implementing a type debugger for Scala(2012)
- When compilers are mirrors(2012)
- Call Graphs for Languages with Parametric Polymorphism(2016)

** language design
- Fighting bit rot with types (experience report: Scala collections)(2009)
- The Scala experiment: can we provide better language support for component systems?(2008)
- Future-proofing collections: from mutable to persistent to parallel(2011)

** virtualization
- Scala-Virtualized: linguistic reuse for deep embeddings(2012)
- Lightweight modular staging: a pragmatic approach to runtime code
  generation and compiled DSLs(2010)
- Language virtualization for heterogeneous parallel computing(2010)
- Lightweight modular staging and embedded compilers(2012) PhD thesis

** macros and metaprogramming
- Scala macros(2012)
- Quasiquotes for scala(2013)
- Yin-Yang: Concealing the deep embedding of DSLs(2014)
- Reflecting scala(2008)
- Translation correctness for first-order object-oriented pattern matching(2007)
- Scala Macros, a Technical Report(2012)

** pattern matching
- Matching Objects with Patterns(2007)
- Object-oriented pattern matching(2007) PhD thesis

** DSL
- Parser combinators in Scala(2008)
- Staged parser combinators for efficient data processing(2014)
- Big Data Analytics with Delite(2013)
- Forge: generating a high performance DSL implementation from a
  declarative specification(2014)
- Spiral in scala: towards the systematic construction of generators
  for performance libraries(2013)

** parallel and distributed computing
- A generic parallel collection framework
- Scala actors: Unifying thread-based and event-based programming(2009)
- On Lock-Free Work-stealing Iterators for Parallel Data Structures(2014)
- Spores: A type-based foundation for closures in the age of concurrency and distribution(2014)
- Isolates, channels, and event streams for composable distributed programming(2015)

** effects
- A flow-insensitive, modular effect system for purity(2013)
- Lightweight polymorphic effects(2012)
- Relative Effect Declarations for Lightweight Effect-Polymorphism(2012)

* Questions
** Where and how libraries are used?
The file `SymbolLoaders.scala` provides the interface for interacting
with libraries.

Specifically, the method `ClassfileLoader#doComplete(root)` loads the
symbol definition for `root` from a class file.

`ClassfileLoader <: SymbolLoader <: LazyType <: UncachedGroundType <: Type`

There are three different concrete loaders corresponding to three
different library formats:

- java class files
- scala2 class files
- tasty files

`ClassSymbol` has a field `associatedFile` which indicated where the
class file is located.

* Development
** Run tests locally: `sbt test`
** How to add a test case?
*** `tests/pos` - test cases for parsing
*** `tests/pos-scala2` - test cases for parsing in Scala2 mode
*** `tests/neg` - test cases that should not compile
*** `tests/run` - test cases that can run with expected  output in `.check` file
*** test beginning with `i` are issues # on `lampepfl/dotty`, e.g. `i1059.scala`
*** test beginning with `t` are issues # on `scala/scala`, e.g. `t1059.scala`
** How to create AST trees in code
- Use helper functions in `untpd._` and `tpd._`.
- Use helper methods in `TreeOps` (preferred)
* Usage
** Compile a file
=./bin/dotc tests/pos/HelloWorld.scala=
** Show AST after parsing
=./bin/dotc -Xprint:parser  examples/hello.scala=
** Show AST after a phase
=./bin/dotc -Xprint:frontend  examples/hello.scala=
=./bin/dotc -Xprint:posttyper,refchecks  examples/hello.scala=
** Stop after a phase
=./bin/dotc -Ystop-after:refchecks  examples/hello.scala=
** Print types of each expression
=./bin/dotc -Xprint:refchecks -Xprint-types examples/hello.scala=
** Print bounds of type variables
=./bin/dotc -Xprint:refchecks -Yshow-var-bounds examples/hello.scala=
** Skip a phase
=./bin/dotc -Xprint:refchecks -Yskip:posttyper examples/hello.scala=
** Output information about classpath
=./bin/dotc -Ylog-classpath examples/hello.scala=
** Check tree at the end of a phase
=./bin/dotc -Ycheck:flatten examples/hello.scala=
** Show tree positions
=./bin/dotc -Xprint:posttyper -Yprintpos examples/hello.scala=
** Check that compiled program does not contain global vars
=./bin/dotc -Ycheck-reentrant examples/hello.scala=
** Explain errors in low-level types
=./bin/dotc -Yexplain-lowlevel examples/hello.scala=
** Explain type errors in more detail
=./bin/dotc -explaintypes examples/hello.scala=
** Use scalajs as backend
=./bin/dotc -scalajs examples/hello.scala=
* Concepts
** Tasty
Interchange format that stores:

- Trees
- Types
- Positions
- Custom sections

- Tells how all methods are actually implemented
- Included for all classes emitted by dotc
- source code for dependencies

[[https://docs.google.com/document/d/1h3KUMxsSSjyze05VecJGQ5H2yh7fNADtIf3chD3_wr0/edit][TASTY Reference Manual]]
** call-graph analysis
CALL-GRAPH ANALYSIS

Detect program entry points, mark them as reachable

For every reachable method:

- mark all methods called from it as reachable
- track how type params flow to other methods
- track which trait combinations were instantiated

Paper: Ali K., Rapoport M., Lhoták O., Dolby J., Tip F. Constructing
Call Graphs of Scala Programs, ECOOP 2014

WHAT CAN LINKER DO?

- smart specialization
- smart dead code elimination. squeryl: 400 methods vs 1500 methods
  reachable by proguard
- convert classes to value classes
- infer more precise types
- eliminate virtual dispatch
- replace vars by vals
- remove duplicate vals

** miniphases
Tree traversal for each phase will break memory locality, slows down
compilation.

Manually fusion miniphase in one pass improves caching & prefetching,
improves performance.
** run VS phase
Each run will go through all the phases
** AST tree VS Symbol tree

http://docs.scala-lang.org/overviews/reflection/symbols-trees-types

The source program is represented by the AST tree. Each tree node has
a type, which is assigned by the typer.

What makes programming interesting is names. Naming is the primary
means of abstraction in programming. Names, just like human names, are
strings that refer to some entities, such as methods, variables,
classes, packages.

Like human names, names can be ambiguous due to duplicate names. Names
can only get exact meaning in a context. The exact meaning of a name
in a context is a symbol. Fixing the meaning of names is the task of
the typer.

A symbol carries abstract information about the named entity, such as
type, owner, members for class symbols, accessiblity information etc.

A symbol NEVER refers to AST definitions of the underlying
entity. Libraries are loaded as symbol trees.

The context has a `owner: symbol` field, indicating the owner of the
current AST tree. That's the only indirect link from symbol to AST
tree.

In dotty, the root of the symbol tree is `RootClass` and
`RootPackage`. Following function recursively find the symbol refered
by a Name (path):

```
DenotationsBase.staticRef(path: Name, generateStubs: Boolean = true)(implicit ctx: Context): Denotation
```

The symbol tree exists in parallel to the AST tree. The usage of names
in the AST tree creates references to the symbol tree. It's the task
of the typer to create the symbol tree from AST tree, and establish
the correct links from the AST tree to the symbol tree. The typer also
sets up types for each node of the symbol tree and AST tree.

Unlike the AST tree, which is a complete top-down structure, the
symbol tree is a down-top structure (via `owner: symbol` field). The
upper-level symbols only have indirect access to lower level symbols
through types if current symbol represents a class or package.

A class symbol has access to all its member symbols, which are stored
as part of the type information of a class(ClassInfo). A class symbol
also has access to its parent class.

In dotty, `Ident` is the AST tree node that invovles names. `Ident`
refers to symbols in the symbol tree. `Ident` takes `NamedType` as
type, which could be `TypeRef` or `TermRef`. `TypeRef` refers to a
prefix#type, `TermRef` refers to prefix#id. Both holds a reference to
the destination symbol.

Scala supports type members. In the AST, type member definition is
represented by `TypeDef`, its type is `TypeAlias`. Type member usage
in AST is represented by `TypeTree[TypeRef(_)]`. The type of the
`TypeTree` is of `TypeRef`, which refers to the symbol of the type
member, whose type is `TypeAlias`.

In dotty, symbol is further split into the pair (symbol, denotation)
to enable one symbol to have different meanings in different
compilation phases. Each symbol has immediate access to its
denotation. Denotations represent the meaning of symbols for a given
phase. Denotation holds information such as name, type, owner symbol,
etc.

Due to the existence of overloaded functions, denotations are still
ambiguous. In dotty, denotations fall into two categories:
MultiDenotation and SingleDenotation. Signatures are used to uniquely
differentiate the meaning of names in a specific context. In AST,
there is a special tree for overloaded function calls:

```
SelectWithSig(qualifier: Tree[T], name: Name, val sig: Signature)
```

** context
To make the core of compiler functional(NOT pure!), mutable
information has to be passed in as context.

The Context contains the state of the compiler, for example

- settings
- freshNames (FreshNameCreator)
- period (run and phase id)
- compilationUnit
- phase
- tree (current tree)
- typer (current typer)
- mode (type checking mode)
- typerState (for example undetermined type variables)

** scala off-heap
12 times faster

- Efficient scoped region-based memory allocator
- Optional low-overhead memory sanitizer for debugging and development
- Offheap classes as a nice typed API for custom data layout
- Offheap arrays with direct sequential layout in memory
- Extensibility to accomodate custom memory allocators

* Types
Type -+- ProxyType --+- NamedType ----+--- TypeRef
      |              |                 \
      |              +- SingletonType-+-+- TermRef
      |              |                |
      |              |                +--- ThisType
      |              |                +--- SuperType
      |              |                +--- ConstantType
      |              |                +--- MethodParam
      |              |                +----RefinedThis
      |              |                +--- SkolemType
      |              +- PolyParam
      |              +- RefinedType
      |              +- TypeBounds
      |              +- ExprType
      |              +- AnnotatedType
      |              +- TypeVar
      |
      +- GroundType -+- AndType
                     +- OrType
                     +- MethodType -----+- ImplicitMethodType
                     |                  +- JavaMethodType
                     +- PolyType
                     +- ClassInfo
                     |
                     +- NoType
                     +- NoPrefix
                     +- ErrorType
                     +- WildcardType
* Tree

A very good introduction about AST trees, though about scalac instead of dotty:

https://github.com/scala-ide/scala-refactoring/raw/thesis-documentation/scala-refactoring.pdf

Initial Code
#+BEGIN_SRC Scala
type Modifiers = Trees.Modifiers[T]
type Tree = Trees.Tree[T]
type TypTree = Trees.TypTree[T]
type TermTree = Trees.TermTree[T]
type PatternTree = Trees.PatternTree[T]
type DenotingTree = Trees.DenotingTree[T]
type ProxyTree = Trees.ProxyTree[T]
type NameTree = Trees.NameTree[T]
type RefTree = Trees.RefTree[T]
type DefTree = Trees.DefTree[T]
type MemberDef = Trees.MemberDef[T]
type ValOrDefDef = Trees.ValOrDefDef[T]

type Ident = Trees.Ident[T]
type BackquotedIdent = Trees.BackquotedIdent[T]
type Select = Trees.Select[T]
type SelectWithSig = Trees.SelectWithSig[T]
type This = Trees.This[T]
type Super = Trees.Super[T]
type Apply = Trees.Apply[T]
type TypeApply = Trees.TypeApply[T]
type Literal = Trees.Literal[T]
type New = Trees.New[T]
type Pair = Trees.Pair[T]
type Typed = Trees.Typed[T]
type NamedArg = Trees.NamedArg[T]
type Assign = Trees.Assign[T]
type Block = Trees.Block[T]
type If = Trees.If[T]
type Closure = Trees.Closure[T]
type Match = Trees.Match[T]
type CaseDef = Trees.CaseDef[T]
type Return = Trees.Return[T]
type Try = Trees.Try[T]
type SeqLiteral = Trees.SeqLiteral[T]
type JavaSeqLiteral = Trees.JavaSeqLiteral[T]
type TypeTree = Trees.TypeTree[T]
type SingletonTypeTree = Trees.SingletonTypeTree[T]
type SelectFromTypeTree = Trees.SelectFromTypeTree[T]
type AndTypeTree = Trees.AndTypeTree[T]
type OrTypeTree = Trees.OrTypeTree[T]
type RefinedTypeTree = Trees.RefinedTypeTree[T]
type AppliedTypeTree = Trees.AppliedTypeTree[T]
type ByNameTypeTree = Trees.ByNameTypeTree[T]
type TypeBoundsTree = Trees.TypeBoundsTree[T]
type Bind = Trees.Bind[T]
type Alternative = Trees.Alternative[T]
type UnApply = Trees.UnApply[T]
type ValDef = Trees.ValDef[T]
type DefDef = Trees.DefDef[T]
type TypeDef = Trees.TypeDef[T]
type Template = Trees.Template[T]
type Import = Trees.Import[T]
type PackageDef = Trees.PackageDef[T]
type Annotated = Trees.Annotated[T]
type Thicket = Trees.Thicket[T]
#+END_SRC
** TypTree
*** ByNameTypeTree
=\=> T=
*** TypeBoundsTree
=T >: lo <: hi=
*** ContextBounds                                                     :untpd:
** TermTree
*** Literal
*** New
*** Pair
*** Assign
=name = arg=, outside a parameter list
*** Block
={ stats; expr }=
*** If
=if cond then thenp else elsep=
*** Closure
*** Match
=selector match { cases }=
**** CaseDef < Tree
*** Return
*** Try
*** SeqLiteral
*** JavaSeqLiteral
*** ParsedTry                                                         :untpd:
*** SymbolLit                                                         :untpd:
*** InterpolatedString                                                :untpd:
*** Throw                                                             :untpd:
*** WhileDo                                                           :untpd:
*** DoWhile                                                           :untpd:
*** ForYield                                                          :untpd:
*** ForDo                                                             :untpd:
** PatternTree
*** Alternative
=tree_1 | ... | tree_n=
*** UnApply
The typed translation of `extractor(patterns)` in a pattern.
** ProxyTree
*** Super < TermTree
*** GenericApply < TermTree
**** Apply
**** TypeApply
*** Typed < TermTree
*** RefinedTypeTree < TypTree
=tpt { refinements }=
*** AppliedTypeTree < TypTree
=tpt[args]=
*** PackageDef
=package pid { stats }=
*** Annotated
=arg @annot=
*** TypedSplice                                                       :untpd:
*** Parens                                                            :untpd:
** DenotingTree
*** NameTree
**** RefTree
***** Ident
****** BackquotedIdent
***** Select
****** SelectWithSig
***** SelectFromTypeTree
=qualifier # name=
***** AndTypeTree
=left & right=
***** OrTypeTree
=left | right=
**** Bind < DefTree PatternTree
=name @ body=
*** This < TermTree
*** DefTree
**** MemberDef < NameTree
***** ValOrDefDef < WithLazyField
****** ValDef
=tpt = rhs=
******* EmptyValDef
****** DefDef
=mods def name[tparams](vparams_1)...(vparams_n): tpt = rhs=
***** TypeDef
****** PolyTypeDef                                                    :untpd:
****** DerivedTypeTree                                                :untpd:
***** ModuleDef                                                       :untpd:
**** Template < WithLazyField
=extends parents { self => body }=
**** PatDef                                                           :untpd:
*** TypeTree < TypTree
A type tree that represents an existing or inferred type
*** SingletonTypeTree
=ref.type=
*** Import
=import expr.selectors=
** NamedArg
=name = arg=, in a parameter list
** WithoutTypeOrPos
** Thicket
** OpTree                                                             :untpd:
*** InfixOp                                                           :untpd:
*** PostfixOp                                                         :untpd:
*** PrefixOp                                                          :untpd:
** Function                                                           :untpd:
** Tuple                                                              :untpd:
** GenFrom                                                            :untpd:
** GenAlias                                                           :untpd:
* Phases
Defined in =Compiler=.

#+BEGIN_SRC Scala
  def phases: List[List[Phase]] =
    List(
      List(new FrontEnd),
      List(new PostTyper),
      List(new Pickler),
      List(new FirstTransform,
           new CheckReentrant),
      List(new RefChecks,
           new ElimRepeated,
           new NormalizeFlags,
           new ExtensionMethods,
           new ExpandSAMs,
           new TailRec,
           new LiftTry,
           new ClassOf),
      List(new PatternMatcher,
           new ExplicitOuter,
           new ExplicitSelf,
           new CrossCastAnd,
           new Splitter),
      List(new VCInlineMethods,
           new SeqLiterals,
           new InterceptedMethods,
           new Getters,
           new ElimByName,
           new AugmentScala2Traits,
           new ResolveSuper),
      List(new Erasure),
      List(new ElimErasedValueType,
           new VCElideAllocations,
           new Mixin,
           new LazyVals,
           new Memoize,
           new LinkScala2ImplClasses,
           new NonLocalReturns,
           new CapturedVars, // capturedVars has a transformUnit: no phases should introduce local mutable vars here
           new Constructors, // constructors changes decls in transformTemplate, no InfoTransformers should be added after it
           new FunctionalInterfaces,
           new GetClass),   // getClass transformation should be applied to specialized methods
      List(new LambdaLift,   // in this mini-phase block scopes are incorrect. No phases that rely on scopes should be here
           new ElimStaticThis,
           new Flatten,
           // new DropEmptyCompanions,
           new RestoreScopes),
      List(new ExpandPrivate,
           new CollectEntryPoints,
           new LabelDefs),
      List(new GenBCode)
    )
#+END_SRC

** FrontEnd                                                       :important:
1. parse          :: parse code
2. enterSyms      :: index sysmbols
3. typeCheck      :: type checking, desugaring
** PostTyper
A macro transform that runs immediately after typer and that performs
the following functions:

1. Add super accessors and protected accessors (@see SuperAccessors)
2. Convert parameter fields that have the same name as a corresponding
   public parameter field in a superclass to a forwarder to the
   superclass field (corresponding = super class field is initialized
   with subclass field) (@see ForwardParamAccessors)
3. Add synthetic methods (@see SyntheticMethods)
4. Check that `New` nodes can be instantiated, and that annotations are valid
5. Convert all trees representing types to TypeTrees.
6. Check the bounds of AppliedTypeTrees
7. Insert `.package` for selections of package object members
8. Replaces self references by name with =this=

The reason for making this a macro transform is that some functions
(in particular super and protected accessors and instantiation checks)
are naturally top-down and don't lend themselves to the bottom-up
approach of a mini phase. The other two functions (forwarding param
accessors and synthetic methods) only apply to templates and fit
mini-phase or subfunction of a macro phase equally well. But taken by
themselves they do not warrant their own group of miniphases before
pickling.
** Pickler
Serialize symbol tables
** +
*** FirstTransform
1. ensures there are companion objects for all classes except module classes
2. eliminates some kinds of trees: Imports, NamedArgs
3. stubs out native methods
*** CheckReentrant
A no-op transform that checks whether the compiled sources are re-entrant.
** +
*** RefChecks
1. overrides and inheritance checks
2. warns about references to symbols labeled deprecated or migration
3. constant propagation for =if=
*** ElimRepeated
Removes repeated parameters (T*) from all types, replacing them with Seq types.
*** NormalizeFlags
1. Widens all private[this] and protected[this] qualifiers to just
   private/protected
2. Sets PureInterface flag for traits that only have pure interface
   members and that do not have initialization code. A pure interface
   member is either an abstract or alias type definition or a deferred
   val or def.
*** ExtensionMethods
Creates extension methods for all methods in a value class, except
parameter or super accessors, or constructors.
*** ExpandSAMs
Expand SAM closures that cannot be represented by the JVM as lambdas
to anonymous classes.

SAM Type: single abstract method types

A type is a *SAM type* if it is a reference to a class or trait, which

- has a single abstract method with a method type (ExprType and
  PolyType not allowed!)
- can be instantiated without arguments or with just () as argument.

*** TailRec
Tail call elimination
*** LiftTry
Lifts try's that might be executed on non-empty expression stacks to
their own methods. I.e.

    try body catch handler

is lifted to

    { def liftedTree$n() = try body catch handler; liftedTree$n() }

*** ClassOf
Rewrite `classOf` calls as follow:

- For every primitive class C whose boxed class is called B:

  classOf[C]    -> B.TYPE

- For every non-primitive class D:

  classOf[D]    -> Literal(Constant(erasure(D)))
** +
*** PatternMatcher
Eliminates patterns.
*** ExplicitOuter
Adds outer accessors to classes and traits that need them.
*** ExplicitSelf
Transforms references of the form

    C.this.m

where `C` is a class with explicit self type and `C` is not a subclass
of the owner of `m` to

   C.this.asInstanceOf[S].m

where `S` is the self type of `C`.

*** CrossCastAnd
Makes sure that all private member selections from AndTypes are
performed from the first component of AndType.

*** Splitter
Makes sure every identifier and select node carries a symbol. To do
this, certain qualifiers with a union type have to be "splitted" with
a type test.

For now, only self references are treated.

If we select a name, make sure the node has a symbol. If necessary,
split the qualifier with type tests.  Example: Assume:

    class A { def f(x: S): T }
    class B { def f(x: S): T }
    def p(): A | B

Then =p().f(a)= translates to

    val ev$1 = p()
    if (ev$1.isInstanceOf[A]) ev$1.asInstanceOf[A].f(a)
    else ev$1.asInstanceOf[B].f(a)

** +
*** VCInlineMethods
Inlines calls to methods of value classes.
*** SeqLiterals
Eliminates SeqLiteral's, transforming =SeqLiteral(elems)= to an
operation equivalent to

    JavaSeqLiteral(elems).toSeq

Instead of =toSeq=, which takes an implicit, the appropriate
"wrapArray" method is called directly. The reason for this step is
that JavaSeqLiterals, being arrays keep a precise type after erasure,
whereas SeqLiterals only get the erased type =Seq=.

*** InterceptedMethods
Replace member references as follows:

- `x != y` for != in class Any becomes `!(x == y)` with == in class Any.
- `x.##` for ## in NullClass becomes `0`
- `x.##` for ## in Any becomes calls to ScalaRunTime.hash, using the
  most precise overload available
- `x.getClass` for getClass in primitives becomes `x.getClass` with
  getClass in class Object.

*** Getters
Performs the following rewritings for fields of a class:

  <mods> val x: T = e
    -->  <mods> <stable> <accessor> def x: T = e
  <mods> var x: T = e
    -->  <mods> <accessor> def x: T = e

  <mods> val x: T
    -->  <mods> <stable> <accessor> def x: T

  <mods> lazy val x: T = e
    -->  <mods> <accessor> lazy def x: T =e

  <mods> var x: T
    -->  <mods> <accessor> def x: T

  <mods> non-static <module> val x$ = e
    -->  <mods> <module> <accessor> def x$ = e

Omitted from the rewritings are

 - private[this] fields in classes (excluding traits, value classes)
 - fields generated for static modules (TODO: needed?)
 - parameters, static fields, and fields coming from Java

Furthermore, assignments to mutable vars are replaced by setter calls

   p.x = e
    -->  p.x_=(e)

No fields are generated yet. This is done later in phase Memoize.

*** ElimByName
This phase eliminates ExprTypes `=> T` as types of function
parameters, and replaces them by nullary function types. More
precisely:

For the types of parameter symbols:

    => T        ==>    () => T

Note that `=> T` types are not eliminated in MethodTypes. This is done
later at erasure.  Terms are rewritten as follows:

    x           ==>    x.apply()   if x is a parameter that had type => T

Arguments to call-by-name parameters are translated as follows. First,
the argument is rewritten by the rules:

1. if e.apply() is an argument to a call-by-name parameter

    e.apply()   ==>    e

2.  if other expr is an argument to a call-by-name parameter

    expr        ==>    () => expr

This makes the argument compatible with a parameter type of () => T,
which will be the formal parameter type at erasure. But to be
-Ycheckable until then, any argument ARG rewritten by the rules above
is again wrapped in an application DummyApply(ARG) where

   DummyApply: [T](() => T): T

is a synthetic method defined in Definitions. Erasure will later strip
these DummyApply wrappers.

Note: This scheme to have inconsistent types between method types
(whose formal types are still ExprTypes and parameter valdefs (which
are now FunctionTypes) is not pretty. There are two other options
which have been abandoned or not yet pursued.

Option 1: Transform => T to () => T also in method and function
types. The problem with this is that is that it requires to look at
every type, and this forces too much, causing Cyclic Reference
errors. Abandoned for this reason.

Option 2: Merge ElimByName with erasure, or have it run immediately
before. This has not been tried yet.

*** AugmentScala2Traits
Augments Scala2 traits with implementation classes and with additional
members needed for mixin composition.

These symbols would have been added between Unpickling and Mixin in
the Scala2 pipeline. Specifcally, it adds

- an implementation class which defines a trait constructor and trait
  method implementations
- trait setters for vals defined in traits

Furthermore, it expands the names of all private getters and setters
as well as super accessors in the trait and makes them not-private.

*** ResolveSuper
Adds super accessors and method overrides where linearization differs
from Java's rule for default methods in interfaces. In particular:

    For every trait M directly implemented by the class (see
    SymUtils.mixin), in reverse linearization order, add the
    following definitions to C:

      3.1 (done in `superAccessors`) For every superAccessor
          `<mods> def super$f[Ts](ps1)...(psN): U` in M:

            <mods> def super$f[Ts](ps1)...(psN): U = super[S].f[Ts](ps1)...(psN)

          where `S` is the superclass of `M` in the linearization of `C`.

      3.2 (done in `methodOverrides`) For every method
          `<mods> def f[Ts](ps1)...(psN): U` in M` that needs to be disambiguated:

            <mods> def f[Ts](ps1)...(psN): U = super[M].f[Ts](ps1)...(psN)

    A method in M needs to be disambiguated if it is concrete, not overridden in C,
    and if it overrides another concrete method.

This is the first part of what was the mixin phase. It is complemented
by Mixin, which runs after erasure.

** Erasure                                                        :important:
Erases parameteric types
** +
*** ElimErasedValueType
Erases ErasedValueType to their underlying type.  It also removes the
synthetic cast methods u2evt$ and evt2u$ which are no longer needed
afterwards.

*** VCElideAllocations
This phase elides unnecessary value class allocations

For a value class V defined as:

  class V(val underlying: U) extends AnyVal

we avoid unnecessary allocations:

   new V(u1) == new V(u2) => u1 == u2
  (new V(u)).underlying() => u

*** Mixin
This phase performs the following transformations:

1. (done in `traitDefs` and `transformSym`) Map every concrete trait getter

       <mods> def x(): T = expr

   to the pair of definitions:

       <mods> def x(): T
       protected def initial$x(): T = { stats; expr }

   where `stats` comprises all statements between either the start of
   the trait or the previous field definition which are not
   definitions (i.e. are executed for their side effects).

2. (done in `traitDefs`) Make every concrete trait setter

       <mods> def x_=(y: T) = ()

   deferred by mapping it to

       <mods> def x_=(y: T)

3. For a non-trait class C:

     For every trait M directly implemented by the class (see SymUtils.mixin), in
     reverse linearization order, add the following definitions to C:

       3.1 (done in `traitInits`) For every parameter accessor `<mods> def x(): T` in M,
           in order of textual occurrence, add

            <mods> def x() = e

           where `e` is the constructor argument in C that corresponds to `x`. Issue
           an error if no such argument exists.

       3.2 (done in `traitInits`) For every concrete trait getter `<mods> def x(): T` in M
           which is not a parameter accessor, in order of textual occurrence, produce the following:

           3.2.1 If `x` is also a member of `C`, and M is a Dotty trait:

             <mods> def x(): T = super[M].initial$x()

           3.2.2 If `x` is also a member of `C`, and M is a Scala 2.x trait:

             <mods> def x(): T = _

           3.2.3 If `x` is not a member of `C`, and M is a Dotty trait:

             super[M].initial$x()

           3.2.4 If `x` is not a member of `C`, and M is a Scala2.x trait, nothing gets added.

       3.3 (done in `superCallOpt`) The call:

             super[M].<init>

       3.4 (done in `setters`) For every concrete setter `<mods> def x_=(y: T)` in M:

             <mods> def x_=(y: T) = ()

4. (done in `transformTemplate` and `transformSym`) Drop all
   parameters from trait constructors.

5. (done in `transformSym`) Drop ParamAccessor flag from all parameter
   accessors in traits.

Conceptually, this is the second half of the previous mixin phase. It
needs to run after erasure because it copies references to possibly
private inner classes and objects into enclosing classes where they
are not visible. This can only be done if all references are symbolic.

*** TODO LazyVals
Transform lazy vals
*** Memoize
Provides the implementations of all getters and setters, introducing
fields to hold the value accessed by them.

TODO: Make LazyVals a part of this phase?

  <accessor> <stable> <mods> def x(): T = e
    -->  private val x: T = e
         <accessor> <stable> <mods> def x(): T = x

  <accessor> <mods> def x(): T = e
    -->  private var x: T = e
         <accessor> <mods> def x(): T = x

  <accessor> <mods> def x_=(y: T): Unit = ()
    --> <accessor> <mods> def x_=(y: T): Unit = x = y

*** LinkScala2ImplClasses
Rewrites calls

  super[M].f(args)

where M is a Scala2 trait implemented by the current class to

  M$class.f(this, args)

provided the implementation class M$class defines a corresponding
function `f`.

*** NonLocalReturns
Implements non-local returns using NonLocalReturnControl exceptions.
*** TODO CapturedVars
*** Constructors
- moves initializers from body to constructor.
- makes all supercalls explicit
- also moves private fields that are accessed only from constructor
  into the constructor if possible.
*** FunctionalInterfaces
Rewires closures to implement more specific types of Functions.
*** GetClass
Rewrite `getClass` calls as follow:

- For every instance of primitive class C whose boxed class is called B:

     instanceC.getClass    -> B.TYPE

- For every instance of non-primitive class D:

     instanceD.getClass    -> instanceD.getClass
** +
*** LambdaLift                                                    :important:
Lifts lambdas to top level
*** ElimStaticThis
Replace `This` references to module classes in static methods by
global identifiers to the corresponding modules.
*** Flatten
Lifts nested classes to toplevel
*** RestoreScopes
The preceding lambda lift and flatten phases move symbols to different
scopes and rename them. This miniphase cleans up afterwards and makes
sure that all class scopes contain the symbols defined in them.

** +
*** ExpandPrivate
Make private term members that are accessed from another class
non-private by resetting the Private flag and expanding their name.

Also, make non-private any private parameter forwarders that forward
to an inherited public or protected parameter accessor with the same
name as the forwarder.  This is necessary since private methods are
not allowed to have the same name as inherited public ones.

See discussion in https://github.com/lampepfl/dotty/pull/784
and https://github.com/lampepfl/dotty/issues/783

*** CollectEntryPoints
Collect entry points, used for backend code generration
*** LabelDefs
Verifies that each Label DefDef has only a single address to jump back
and reorders them such that they are not nested and this address is a
fall-through address for JVM.

e.g. following code

    <label> def foo(i: Int) = {
      <label> def bar = 0
      <label> def dough(i: Int) = if (i == 0) bar else foo(i-1)
      dough(i)
      }

    foo(100)

will get rewritten to
                                                 \
    <label> def foo(i: Int) = dough(i)
    <label> def dough(i: Int) = if (i == 0) bar else foo(i-1)
    <label> def bar = 2
      foo(100)

Proposed way to generate this pattern in backend is:

     foo(100)
     <jump foo>
     <label> def foo(i: Int) = dough(i)
     // <jump a>                           // unreachable
     <label> def dough(i: Int) = if (i == 0) bar else foo(i-1)
     // <jump a>                           // unreachable
     <label> def bar = 2
     // <jump a>                           // unreachable
     <asm point a>

Unreachable jumps will be eliminated by local dead code analysis.
After JVM is smart enough to remove next-line jumps

Note that Label DefDefs can be only nested in Block, otherwise no one
would be able to call them Other DefDefs are eliminated

** GenBCode
Generates the code
* src
** dotty
*** TODO annotation.internal
*** TODO runtime
*** tools
**** TODO backend.jvm
**** dotc
***** ast
Tree definitions and desugaring
****** desugar
****** Positioned
****** tpd
typed tree
****** TreeInfo
****** Trees
****** untpd
untyped tree
***** config
Configuration settings of compilation
***** core
****** classfile
java classfile manipulation
****** tasty
tasty format manipulation
****** Annotations
modelling of annotations
****** CheckRealizable
Check realizability of types, used in typer.Checking
****** Constants
value tags definition
****** Constraint
base class for representing constraints in local type inference
****** ConstraintHandling
Methods for adding constraints and solving them.

What goes into a Constraint as opposed to a ConstrainHandler?

Constraint code is purely functional: Operations get constraints and
produce new ones.  Constraint code does not have access to a
type-comparer. Anything regarding lubs and glbs has to be done
elsewhere.

By comparison: Constraint handlers are parts of type comparers and can
use their functionality.  Constraint handlers update the current
constraint as a side effect.
****** Contexts
A context is passed basically everywhere in dotc. This is convenient
but carries the risk of captured contexts in objects that turn into
space leaks. To combat this risk, here are some conventions to follow:

- Never let an implicit context be an argument of a class whose
  instances live longer than the context.

- Classes that need contexts for their initialization take an explicit
  parameter named `initctx`. They pass initctx to all positions where
  it is needed (and these positions should all be part of the
  intialization sequence of the class).

- Classes that need contexts that survive initialization are instead
  passed a "condensed context", typically named `cctx` (or they create
  one). Condensed contexts just add some basic information to the
  context base without the risk of capturing complete trees.

- To make sure these rules are kept, it would be good to do a sanity
  check using bytecode inspection with javap or scalap: Keep track of
  all class fields of type context; allow them only in whitelisted
  classes (which should be short-lived).

****** Decorators
provides useful implicit decorators for types defined elsewhere

****** Definitions
defines symbols and types of standard definitions

****** Denotations
Denotations represent the meaning of symbols and named types.  The
following diagram shows how the principal types of denotations and
their denoting entities relate to each other. Lines ending in a
down-arrow `v` are member methods. The two methods shown in the
diagram are "symbol" and "deref". Both methods are parameterized by
the current context, and are effectively indexed by current period.

Lines ending in a horizontal line mean subtying (right is a subtype of left).

NamedType------TermRefWithSignature
  |                    |                     Symbol---------ClassSymbol
  |                    |                       |                |
  | denot              | denot                 | denot          | denot
  v                    v                       v                v
Denotation-+-----SingleDenotation-+------SymDenotation-+----ClassDenotation
           |                      |
           +-----MultiDenotation  |
                                  |
                                  +--UniqueRefDenotation
                                  +--JointRefDenotation

Here's a short summary of the classes in this diagram.

NamedType                A type consisting of a prefix type and a name, with fields
                            prefix: Type
                            name: Name
                         It has two subtypes: TermRef and TypeRef
TermRefWithSignature     A TermRef that has in addition a signature to select an overloaded variant, with new field
                            sig: Signature
Symbol                   A label for a definition or declaration in one compiler run
ClassSymbol              A symbol representing a class
Denotation               The meaning of a named type or symbol during a period
MultiDenotation          A denotation representing several overloaded members
SingleDenotation         A denotation representing a non-overloaded member or definition, with main fields
                            symbol: Symbol
                            info: Type
UniqueRefDenotation      A denotation referring to a single definition with some member type
JointRefDenotation       A denotation referring to a member that could resolve to several definitions
SymDenotation            A denotation representing a single definition with its original type, with main fields
                            name: Name
                            owner: Symbol
                            flags: Flags
                            privateWithin: Symbol
                            annotations: List[Annotation]
ClassDenotation          A denotation representing a single class definition.

****** DenotTransformers
defines following traits for denotation transformation
- DenotTransformer < Phase
  - InfoTransformer
  - SymTransformer

****** Flags
defines =FlagSet=

A FlagSet represents a set of flags. Flags are encoded as follows: The
first two bits indicate whether a flagset applies to terms, to types,
or to both.  Bits 2..63 are available for properties and can be doubly
used for terms and types.

Combining two FlagSets with `|` will give a FlagSet that has the
intersection of the applicability to terms/types of the two flag
sets. It is checked that the intersection is not empty.

****** Hashable
defines the trait =Hashable=

****** NameOps
operations related to names

****** Names
defines =Name=.

A name is essentially a string, with three differences:

1. Names belong in one of two name spaces: they are type names or term
   names. Term names have a sub-category of "local" field names. The
   same string can correspond a name in each of the three namespaces.

2. Names are hash-consed. Two names representing the same string in
   the same universe are always reference identical.

3. Names are intended to be encoded strings. @see
   dotc.util.NameTransformer. The encoding will be applied when
   converting a string to a name.

****** OrderingConstraint
Constraint over undetermined type parameters that keeps separate maps
to reflect parameter orderings.

****** Periods
Periods are the central "clock" of the compiler. A period consists of
a run id and a phase id.  run ids represent compiler runs phase ids
represent compiler phases.

****** Phases
Compilation phases

****** Scopes
A scope contains a set of symbols. It can be an extension of some
outer scope, from which it inherits all symbols.  This class does not
have any methods to add symbols to a scope or to delete them. These
methods are provided by subclass MutableScope.

****** Signature
The signature of a denotation.

Overloaded denotations with the same name are distinguished by their
signatures. A signature of a method (of type PolyType,MethodType, or
ExprType) is composed of a list of signature names, one for each
parameter type, plus a signature for the result type. Methods are
uncurried before taking their signatures.  The signature name of a
type is the fully qualified name of the type symbol of the type's
erasure.

For instance a definition

    def f(x: Int)(y: List[String]): String

would have signature

    Signature(
      List("scala.Int".toTypeName, "scala.collection.immutable.List".toTypeName),
      "scala.String".toTypeName)

The signatures of non-method types are always `NotAMethod`.

****** StdNames
standard names

****** Substituters
Substitution operations on types

****** TODO SymbolLoaders
****** Symbols
Creation methods for symbols. It's mixed in =Context=.

****** SymDenotations
methods for SymDenotion creation

****** TypeApplications                                           :important:
type application

****** TypeComparer                                               :important:
Provides methods to compare types

****** TypeErasure                                                :important:
Erased types are:

ErasedValueType
TypeRef(prefix is ignored, denot is ClassDenotation)
TermRef(prefix is ignored, denot is SymDenotation)
JavaArrayType
AnnotatedType
MethodType
ThisType
SuperType
ClassInfo (NoPrefix, ...)
NoType
NoPrefix
WildcardType
ErrorType

only for isInstanceOf, asInstanceOf: PolyType, PolyParam, TypeBounds

****** TODO TypeOps
****** TODO TyperState
MutableTyperState

****** TODO Types                                                 :important:
****** Uniques
Defines operation `unique` for hash-consing types.  Also defines
specialized hash sets for hash consing uniques of a specific type.
All sets offer a `enterIfNew` method which checks whether a type with
the given parts exists already and creates a new one if not.

***** parsing
recursive-descent parsing
***** printing
printing of various objects
***** repl
read-eval-print loop
***** reporting
handle diagnostics output
***** transform
****** AugmentScala2Traits
This phase augments Scala2 traits with implementation classes and with
additional members needed for mixin composition.

These symbols would have been added between Unpickling and Mixin in
the Scala2 pipeline.  Specifcally, it adds

 - an implementation class which defines a trait constructor and trait
   method implementations
 - trait setters for vals defined in traits

Furthermore, it expands the names of all private getters and setters
as well as super accessors in the trait and makes them not-private.
****** TODO CapturedVars
****** CheckReentrant
A no-op transform that checks whether the compiled sources are re-entrant.
****** ClassOf
Rewrite =classOff=
****** CollectEntryPoints
collect entry points
****** Constructors
This transform
- moves initializers from body to constructor.
- makes all supercalls explicit
- also moves private fields that are accessed only from constructor
  into the constructor if possible.
****** CrossCastAnd
This transform makes sure that all private member selections from
AndTypes are performed from the first component of AndType.  This is
needed for correctness of erasure. See `tests/run/PrivateAnd.scala`
****** CtxLazy
Utility class for lazy values whose evaluation depends on a context.
****** ElimByName
eliminates ExprTypes `=> T` as types of function parameters, and
replaces them by nullary function types
****** ElimErasedValueType
erases value class to their underlying type.
****** ElimRepeated
replaces repeated parameters (*T) with Seq types
****** ElimStaticThis
peplace =This= references to module classes in static methods by global
identifiers to the corresponding modules.
****** ExpandPrivate
Make private term members that are accessed from another class
non-private by resetting the Private flag and expanding their name.
****** ExpandSAMs
Expand SAM closures that cannot be represented by the JVM as lambdas
to anonymous classes.
****** ExplicitOuter
adds outer accessors to classes and traits that need them
****** ExplicitSelf
Transform references of the form

   C.this.m

where `C` is a class with explicit self type and `C` is not a subclass
of the owner of `m` to

   C.this.asInstanceOf[S].m

where `S` is the self type of `C`.
****** ExtensionMethods
Perform Step 1 in the value classes SIP: Creates extension methods for
all methods in a value class, except parameter or super accessors, or
constructors.
****** FirstTransform
The first tree transform
- ensures there are companion objects for all classes except module classes
- eliminates some kinds of trees: Imports, NamedArgs
- stubs out native methods
****** Flatten
Lift nested classes to toplevel
****** FullParameterization
Provides methods to produce fully parameterized versions of instance
methods, where the `this` of the enclosing class is abstracted out in
an extra leading `$this` parameter and type parameters of the class
become additional type parameters of the fully parameterized method.
****** FunctionalInterfaces
Rewires closures to implement more specific types of Functions.
****** GetClass
Rewrite `getClass` calls as follow:

For every instance of primitive class C whose boxed class is called B:

   instanceC.getClass    -> B.TYPE

For every instance of non-primitive class D:

   instanceD.getClass    -> instanceD.getClass
****** Getters
Rewrite fields of a class
****** InterceptedMethods
Replace member references as follows:

- `x != y` for != in class Any becomes `!(x == y)` with == in class Any.
- `x.##` for ## in NullClass becomes `0`
- `x.##` for ## in Any becomes calls to ScalaRunTime.hash,
    using the most precise overload available
- `x.getClass` for getClass in primitives becomes `x.getClass` with
  getClass in class Object.

****** LambdaLift
Lift lambdas to toplevel

****** LazyVals
transform lazy variables

****** LiftTry
Lifts try's that might be executed on non-empty expression stacks
to their own methods. I.e.

    try body catch handler

is lifted to

    { def liftedTree$n() = try body catch handler; liftedTree$n() }

****** LinkScala2ImplClasses
Rewrite calls

    super[M].f(args)

where M is a Scala2 trait implemented by the current class to

    M$class.f(this, args)

provided the implementation class M$class defines a corresponding
function `f`.

****** MacroTransform
A base class for transforms.

****** Memoize
Provides the implementations of all getters and setters, introducing
fields to hold the value accessed by them.

****** Mixin
transformations with mixin

****** MixinOps
operations with mixin

****** NonLocalReturns
Implement non-local returns using NonLocalReturnControl exceptions.

****** NormalizeFlags
1. Widens all private[this] and protected[this] qualifiers to just
   private/protected
2. Sets PureInterface flag for traits that only have pure interface
   members and that do not have initialization code. A pure interface
   member is either an abstract or alias type definition or a deferred
   val or def.
****** TODO OverridingPairs
****** ParamForwarding
For all parameter accessors

    val x: T = ...

if

1. x is forwarded in the supercall to a parameter that's also named `x`
2. the superclass parameter accessor for `x` is accessible from the
   current class

change the accessor to

    def x: T = super.x.asInstanceOf[T]

Do the same also if there are intermediate inaccessible parameter
accessor forwarders.  The aim of this transformation is to avoid
redundant parameter accessor fields.
****** PatternMatcher
eliminates patterns
****** Pickler
****** PostTyper
A macro transform that runs immediately after typer
****** ResolveSuper
adds super accessors and method overrides where linearization differs
from Java's rule for default methods in interfaces.
****** RestoreScopes
The preceding lambda lift and flatten phases move symbols to different
scopes and rename them. This miniphase cleans up afterwards and makes
sure that all class scopes contain the symbols defined in them.
****** SeqLiterals
A transformer that eliminates SeqLiteral's, transforming
`SeqLiteral(elems)` to an operation equivalent to

    JavaSeqLiteral(elems).toSeq

Instead of `toSeq`, which takes an implicit, the appropriate
"wrapArray" method is called directly. The reason for this step is
that JavaSeqLiterals, being arrays keep a precise type after erasure,
whereas SeqLiterals only get the erased type `Seq`.
****** Splitter
makes sure every identifier and select node carries a symbol. To do
this, certain qualifiers with a union type have to be "splitted" with
a type test.
****** SuperAccessors
transformations related to =super=
****** SymUtils
A decorator that provides methods on symbols that are needed in the
transformer pipeline.
****** SyntheticMethods
Synthetic method implementations for case classes, case objects, and
value classes.Synthetic method implementations for case classes, case
objects, and value classes.
****** TailRec
tail call elimination
****** TreeChecker
Run by -Ycheck option after a given phase, this class retypes all
syntax trees and verifies that the type of each tree node so obtained
conforms to the type found in the tree node.
****** TODO TreeExtractors
****** TODO TreeGen
****** TreeTransforms
Base class of tree transforms. For each kind of tree K, there are two
methods which can be overridden:

prepareForK // return a new TreeTransform which gets applied to the K
// node and its children
transformK // transform node of type K

If a transform does not need to visit a node or any of its children,
it signals this fact by returning a NoTransform from a prepare method.

If all transforms in a group are NoTransforms, the tree is no longer
traversed.
****** TypeTestsCasts
This transform normalizes type tests and type casts, also replacing
type tests with singleton argument type with reference equality check

Any remaining type tests

- use the object methods $isInstanceOf and $asInstanceOf
- have a reference type as receiver
- can be translated directly to machine instructions
****** TypeUtils
A decorator that provides methods on types that are needed in the
transformer pipeline.
****** ValueClasses
Methods that apply to user-defined value classes
****** VCElideAllocations
elides unnecessary value class allocations
****** VCInlineMethods
inlines calls to methods of value classes.
***** typer
****** TODO Applications
****** Checking
various check: realizability, bounds, etc
****** ConstFold
constant folding
****** ErrorReporting
error reporting
****** EtaExpansion
converts a method reference to a function value.

    abs  ~~~~>  \x -> abs x
****** FrontEnd
First phase of compilation: parsing, indexing and typing.
****** Implicits
Implicit resolution
****** ImportInfo
info relating to an import clause
****** Inferencing
type inference
****** TODO Mode
****** Namer
create symbols from definitions and gives them lazy types
****** TODO ProtoTypes
****** RefChecks
checks related to overrides
****** ReTyper
A version of Typer that keeps all symbols defined and referenced in a
previously typed tree.
****** TypeAssigner
type assignments
****** Typer
type checking facade
****** VarianceChecker
check that all top-level definitions in tree are variance correct.
****** Variances
variance operations
***** util
****** Attachment
A class inheriting from Attachment.Container supports adding, removing
and lookup of attachments. Attachments are typed key/value pairs.
****** Chars
Contains constants and classifier methods for characters
****** common
Common values hoisted out for performance
****** DotClass
Adds standard functionality to a class.
****** FreshNameCreator
Creates fresh name
****** HashSet
A hash set that allows some privileged protected access to its internals
****** kwords
test for Scala worksheet
****** LRUCache
A least-recently-used cache for Key -> Value computations
****** NameTransformer
Provides functions to encode and decode Scala symbolic names
****** Positions
A position indicates a range between a start offset and an end offset.
****** Set
A common class for lightweight sets
****** ShowPickled
display pickled info
****** SimpleMap
simple map interface
****** SixteenNibbles
An efficient implementation of sequences of 16 indexed elements with
values 0..15 in a single Long.
****** SourceFile
abstraction of a source file
****** SourcePosition
A source position is comprised of a position in a source file.
****** TODO Stats
****** Util
a best fit algorithm

***** Bench
=object Bench extends Driver=
For performance testing
***** CompilationUnit
- Represents a compilation unit.
- untyped tree: =var untpdTree: untpd.Tree=
- typed tree: =var tpdTree: tpd.Tree=

****** TODO picklers: =var picklers: Map[ClassSymbol, TastyPickler]=
****** TODO unpickers: =var unpicklers: Map[ClassSymbol, TastyUnpickler]=

***** Compiler                                                    :important:
This class defines the compiler processing flow, and set up the context.
***** Driver                                                      :important:
=abstract class Driver extends DotClass=
Uses =Compiler= to run compilation
***** FromTasty
=object FromTasty extends Driver=
Compiler for Tasty files
***** Resident
=class Resident extends Driver=
A compiler which stays resident between runs
***** Run
=class Run(comp: Compiler)(implicit ctx: Context)=
Used in =Compiler= to define a running of the compiler
**** TODO io
*** TODO object DottyPredef
*** TODO object language
*** TODO class Pair[T, U](x: T, y: U)
*** TODO class Singleton

** TODO scala
** TODO strawman.collection
* links
 * [[https://gist.github.com/djspiewak/2ae2570c8856037a7738][Collections Redesign Proposal]]
